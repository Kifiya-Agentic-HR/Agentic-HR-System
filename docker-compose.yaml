services:

  cms_backend:
    build: ./services/cms/backend
    container_name: CMSBackend
    ports:
      - "${CMS_BACKEND_PORT}:3000"
    depends_on:
      - mongo
      - redis
      - notification
    env_file: .env
    environment:
      PORT: 3000
      MONGO_URI: "mongodb://mongo:27017/hr_db"
      MONGO_DB: "hr_db"
      MONGO_INITDB_DATABASE: "hr_db"
      REDIS_HOST: "redis"
      REDIS_PORT: "6379"
      REDIS_URI: "redis://redis:6379"
      NOTIFICATION_PORT: "8000" 
      NOTIFICATION_SERVICE_URL: "http://notification:${NOTIFICATION_PORT}/api/v1/"
      FRONTEND_BASE_URL: "http://${HOST}:${CMS_FRONTEND_PORT}"
      CAREERS_PAGE: "http://${HOST}:${JOB_PORTAL_PORT}"
      INTERVIEW_BACKEND_URL: "http://interview_backend:8080/api/v1"
      JWT_SECRET: "${JWT_SECRET}"
      ADMIN_EMAIL: "${ADMIN_EMAIL}"
      ADMIN_PASSWORD: "${ADMIN_PASSWORD}"
    networks:
      - app_network
    
  cms_frontend:
    build:
      context: ./services/cms/frontend
      args:
        NEXT_PUBLIC_API_BASE_URL: "${SECURE_ENDPOINT}"
        NEXT_PUBLIC_GEMINI_API_KEY: "${GEMINI_API_KEY}"
    container_name: CMSFrontend
    ports:
      - "${CMS_FRONTEND_PORT}:3000"
    depends_on:
      - cms_backend
    env_file: .env
    environment:
      NEXT_PUBLIC_API_BASE: "${SECURE_ENDPOINT}"
      NEXT_PUBLIC_GEMINI_API_KEY: "${GEMINI_API_KEY}"
    networks:
      - app_network
    volumes:
      - shared_volume_new:/shared_volume

  interview_backend:
    build: ./services/interview_ai/backend
    container_name: InterviewBackend
    depends_on:
      - mongo
      - redis
      - notification
    env_file: .env
    environment:
      MONGO_URI: "mongodb://mongo:27017/hr_db"
      MONGO_DB: "hr_db"
      REDIS_URI: "redis://redis:6379"
      OPENAI_API_KEY: "${OPENAI_API_KEY}"
      MODEL: "${MODEL}"
      NOTIFICATION_SERVICE_URL: "http://notification:${NOTIFICATION_PORT}/api/v1/"
      FRONTEND_BASE_URL: "http://${HOST}:${INTERVIEW_FRONTEND_PORT}"
      WEAVIATE_HOST: "weaviate"
      WEAVIATE_PORT: 8081
    networks:
      - app_network
    volumes:
      - shared_volume_new:/shared_volume
      - ./logs/interview:/interview-ai/logs/


  interview_frontend:
    build:
      context: ./services/interview_ai/frontend
      args:
        NEXT_PUBLIC_API_BASE_URL: "${SECURE_ENDPOINT}/api/v1"
        NEXT_PUBLIC_INTERVIEW_BACKEND: "${SECURE_ENDPOINT}"
    container_name: InterviewFrontend
    ports:
      - "${INTERVIEW_FRONTEND_PORT}:3000"
    depends_on:
      - interview_backend
    env_file: .env
    environment:
      NEXT_PUBLIC_API_BASE_URL: "${SECURE_ENDPOINT}/api/v1"
      NEXT_PUBLIC_INTERVIEW_BACKEND: "${SECURE_ENDPOINT}"
    networks:
      - app_network

  job_service_backend:
    build: ./services/job_service/backend
    container_name: job_service_backend
    env_file: .env
    environment:
      RABBITMQ_URL: "amqp://guest:guest@rabbitmq:5672/"
      MONGODB_URI: "mongodb://mongo:27017/hr_db"
      GEMINI_API_KEY: "${GEMINI_API_KEY}"
      NOTIFICATION_SERVICE_URL: "http://notification:${NOTIFICATION_PORT}/api/v1/"
      UPLOAD_USER: "${UPLOAD_USER}"
      UPLOAD_PASSWORD: "${UPLOAD_PASSWORD}"
      UPLOAD_URL: "${UPLOAD_URL}"
    volumes:
      - shared_volume_new:/shared_volume
      - ./logs/job_service:/job_service/logs
    restart: unless-stopped
    depends_on:
      mongo:
        condition: service_started
      rabbitmq:
        condition: service_healthy
    networks:
      - app_network

  job_service_frontend:
    build:
      context: ./services/job_service/frontend
      args:
        NEXT_PUBLIC_BASE_API_URL: "${SECURE_ENDPOINT}"
    container_name: job_service_frontend
    ports:
      - "${JOB_PORTAL_PORT}:3000"
    env_file: .env
    environment:
      BASE_API_URL: "${SECURE_ENDPOINT}"
    networks:
      - app_network
    restart: unless-stopped

  # screening_consumer:
  #   build:
  #     context: ./services/screen_service/
  #     dockerfile: Dockerfile.consumer
  #   container_name: ScreeningConsumer
  #   env_file: .env
  #   environment:
  #     RABBITMQ_URL: "amqp://guest:guest@rabbitmq:5672/"
  #     NEXT_PUBLIC_API_BASE: "${SECURE_ENDPOINT}"
  #     MONGODB_URI: "mongodb://mongo:27017/hr_db"
  #     GEMINI_API_KEY: "${GEMINI_API_KEY}"
  #     PYTHONPATH: "/src"
  #   volumes:
  #     - shared_volume_new:/shared_volume
  #     - ./logs/screen_service:/screen_service/logs
  #   depends_on:
  #     mongo:
  #       condition: service_started
  #     rabbitmq:
  #       condition: service_healthy
  #   networks:
  #     - app_network

  mongo:
    image: mongo:latest
    command: mongod --quiet --logpath /dev/null
    container_name: Mongo
    ports:
      - "27027:27017"
    restart: always
    volumes:
      - ./data/mongo:/data/db
    environment:
      MONGO_INITDB_DATABASE: hr_db
    networks:
      - app_network

  redis:
    image: redis:latest
    container_name: Redis
    restart: always
    ports:
      - "6379:6379"
    networks:
      - app_network
    logging:
      driver: "json-file"
      options:
        max-size: "200k"
        max-file: "10"
    volumes:
      - redis-data_new:/data

  notification:
    build: ./services/notification
    ports:
      - "7788:8000"
    volumes:
      - ./logs/notification:/notification/logs
    env_file: .env
    environment:
      PORT: 8000
      SMTP_HOST: ${SMTP_HOST}
      SMTP_PORT: ${SMTP_PORT}
      SMTP_USERNAME: ${SMTP_USERNAME}
      SMTP_PASSWORD: ${SMTP_PASSWORD}
      SMTP_FROM: ${SMTP_FROM}
      REDIS_URI: "redis://redis:6379/0"
    networks:
      - app_network
    depends_on:
      - redis

  rabbitmq:
    image: rabbitmq:4.0-management
    ports:
      - "5672:5672"
      - "15673:15672"
    volumes:
      - rabbitmq_data_new:/var/lib/rabbitmq
    networks:
      - app_network
    healthcheck:
      test: ["CMD", "rabbitmqctl", "status"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 10s

  # --- ELK Stack Services ---
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.1
    container_name: elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - esdata:/usr/share/elasticsearch/data
    networks:
      - app_network

  kibana:
    image: docker.elastic.co/kibana/kibana:8.11.1
    container_name: kibana
    ports:
      - "5601:5601"
    depends_on:
      - elasticsearch
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    networks:
      - app_network

  filebeat:
    image: docker.elastic.co/beats/filebeat:8.11.1
    container_name: filebeat
    user: root
    depends_on:
      - elasticsearch
      - kibana
    volumes:
      - ./filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
      - ./logs:/usr/share/filebeat/logs:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
    networks:
      - app_network

networks:
  app_network:
    driver: bridge

volumes:
  shared_volume_new:
  rabbitmq_data_new:
  redis-data_new:
  esdata: