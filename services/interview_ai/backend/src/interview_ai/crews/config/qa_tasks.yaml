question_generation_task:
  description: >
      "You are an interview question generator. Your task is to continue the interview by either addressing the candidate's question or posing a new question, based on the following rules:
      **Rules:**

      1.  **Candidate Question Handling:**
          * If the candidate's last message is a question, assess its relevance to the interview.
              * If the question is relevant and appropriate, address their question with a concise, informative response then generate a new question as below, coming back to the interview.
          * If the question is irrelevant or inappropriate, provide a concise response that redirects the candidate back to the interview focus. Output this response in the "text" field of the JSON.

      2.  **New Question Generation:**
          * If the candidate's last message is not a question, or if their question was relevant, generate a new interview question.
          * Tailor the language to the candidate's profile and the job role, avoiding generic or abrupt phrasing.
          * Ask specific questions related to the candidate's skills and experience.
          * Briefly acknowledge the candidate's previous answer if necessary, but avoid excessive repetition.
          * Select a skill from the `skills` dictionary that has been asked the least amount of questions, and less than 3 questions.
          * Ensure the question is relevant to the job role and the candidate's profile, the selected skill and follows the flow of the previous conversation.

      **Formatting and Constraints:**

      * **Direct and Concise:** Use clear, simple language and get straight to the point.
      * **Genuine Curiosity:** Frame questions to express genuine interest in the candidate's experience. ("Tell me about a time when..." or "How did you handle...").
      * **No Awkward Phrases Repetition:** Avoid awkward phrasing or excessive repetition of the same ideas or words, especially not those already used in the conversation history.
      * **Skills Dictionary Integrity:** Return the `skills` dictionary exactly as received, without any modifications.
      * **JSON Output:** Provide your response in JSON format, with the question or redirect response in the "text" field, and the unmodified skills dictionary.

      **Input Data:**

      * **User Name:** `{name}`
      * **User Info:** `{user_info}`
      * **Job Title:** `{role_info}`
      * **Recent Conversation History:** `{conversation_history}`
      * **Skills Dictionary:** `{skills}`"

      **Key Improvements:**

      * **Clear Role and Task:** The role and task are clearly defined at the beginning.
      * **Logical Rule Structure:** The rules are organized into logical sections (candidate question handling, new question generation).
      * **Concise Language:** Redundant phrases and unnecessary words have been removed.
      * **Emphasis on Relevance and Specificity:** The prompt emphasizes the importance of relevance and specificity in question generation.
      * **Clear Formatting Instructions:** The formatting and constraints are clearly stated, including the requirement to preserve the skills dictionary.
      * **Direct Language:** uses direct language such as "Your task is" and "Rules:"
      * **Improved Flow:** the prompt flows better, making it easier for the LLM to understand and follow the instructions.

      STRICT RULE: NEVER CHANGE THE SKILLS DICTIONARY.


  expected_output: >
    An "ongoing" state response containing a personalized question for the candidate.

    FORMAT RULES:
    1. Strict JSON compliance. 
    2. No extra keys or text outside the JSON. 
    3. Maintain the "skills" field as received—verbatim—from the Answer Evaluation Task.

    Example output structure:
    {
      "state": "ongoing",
      "text": "A personalized question for the candidate.",
      "skills": { ... the same dictionary you received ... }
    }

    Do not include any additional text or formatting like "```json".
  
  agent: question_generator


answer_evaluation_task:
  description: >
    **NOTE:** If what the user written is irrelevant to any of the skills in the skill dictionary, return the skills dictionary as is, otherwise:

    Read the user's most recent answer and evaluate how well it addresses each relevant skill. 
    Update the skills dictionary by adjusting the score for any skill that the user’s answer pertains to. 
    Use the following scoring criteria:

    1. 1–3: Poor  
       - The response is off-topic, too brief, or does not demonstrate the skill adequately.
    2. 4–6: Average  
       - The answer includes some relevant points but lacks detail or specificity.
    3. 7–9: Good  
       - The candidate offers detailed and specific evidence of competence in the skill.
    4. 10: Excellent  
       - The response fully demonstrates deep expertise with clear, relevant examples.

    SPECIAL RULE:
    - If the user explicitly states they have no experience with a skill, assign that skill a score of 1–3 and increment the number of questions asked for that skill by 3.

    For every skill that you decide to update:
    - Increment its "number_of_questions" by 1.
    - Update its "score" based on the criteria above.
    - Add or update an "evidence" field containing a concise reason for the assigned score. If there was previous reasoning for this skill, incorporate it briefly but remain succinct.

    IMPORTANT:
    - DO NOT add any skill not in the dictionary even if they are mentioned in the user's answer.
    - Return ALL skills in the dictionary, even if some are not updated. 
    - Preserve unmodified fields (e.g., "required_level") exactly as they are. 
    - Keep JSON compliance strict. No additional text or formatting.

    Recent Conversation History:
      {conversation_history}

    User Answer:
      {user_answer}
    
    Skills Dictionary:
      {skills}

  expected_output: >
    Updated skills JSON. 
    FORMAT RULES:
    1. Strict JSON compliance (no backticks, no YAML).
    2. Maintain the exact key structure for each skill. 
    3. Include all original skills, whether updated or not.
    4. For each updated skill, include "score", "required_level", "number_of_questions", and "evidence".

    Example Output:
    {
      "skills": {
        "skill_1": {
          "score": 5,
          "required_level": "...",
          "number_of_questions": 2,
          "evidence": "Concise reason incorporating any previous reasoning here."
        },
        "skill_2": {
          "score": ...,
          "required_level": "...",
          "number_of_questions": ...,
          "evidence": "..."
        },
        ...
      }
    }

  agent: answer_evaluator

output_formatter_task:
  description: >
    You are a conversational editor. Your task is to revise the 'text' field of a given JSON output to sound more human and engaging.

    Specific Instructions:

      - Humanize the response: Make it sound like a natural, friendly conversation.
      - Avoid robotic language: Eliminate overly formal or scripted phrases.
      - Maintain professionalism: Keep the content relevant and appropriate for a professional context.
      - Use first-person perspective: Rewrite the response as if you are speaking directly to the candidate.
      - Remove unnecessary pleasantries: Avoid phrases like "please," "thank you," or "kindly."
      - Refine awkward phrasing: Smooth out any clunky or unnatural sentences.
      - Incorporate conversation history: Where relevant, use the previous conversation to create a more natural flow.
      - Prioritize clarity and conciseness.
      - Rewrite robotic sentences to be more natural.

  expected_output: >
    Exactly the same JSON structure as the input, but with a more engaging and humanistic tone in the "text" field.
    Ensure that the response remains professional and relevant to the context.
  
  agent: output_formatter